## Similarity and Relevance of Court Decisions: A Computational Study on CJEU Cases

+++++++++++++++++++++++++++++++  
<ins>Authors</ins>: K. Moodley et al.  
<ins>Date</ins>: 2019-12  
<ins>Tags</ins>: `text similarity`  
+++++++++++++++++++++++++++++++  


### Intro

- Identification of relevant or similar court decisions is a core activity in legal decision making for case law researchers and practitioners. With an ever increasing body of case law, a manual analysis of court decisions can become practically impossible. As a result, some decisions are inevitably overlooked.
- The advent of text similarity measures (both syntactic and semantic) has meant that potentially relevant cases can be identified without the need to manually read them. However, how close do these measures come to approximating the notion of relevance captured in the citation network?


### Contributions

- In this paper, they use some popular text similarity algorithms to generate a *court decision similarity network (CDSN)* - an analogue of the *court decision citation network (CDCN)* - in which links between decisions imply high textual similarity. The goal of their study is to evaluate the size of overlap between
the CDSNs generated by selected text similarity algorithms and the CDCN.
- They focus on judgements by the Court of Justice of the European Union (CJEU) as published in the EUR-Lex database.
- Their results show that similarity of the full texts of CJEU court decisions does not closely mirror citation behaviour, there is a substantial overlap. In particular, they found syntactic measures surprisingly outperform semantic ones in approximating the citation network.

***

### Notion of relevance

- In law generally, the concept of relevance has been previously studied and there have been attempts to define it for Legal Information Retrieval (LIR) tasks. However, to date, there has been no measurable specialisation of this definition for case law.
- Many such LIR systems are implemented in proprietary software such as [ROSS](https://rossintelligence.com) and [Lex Machina](https://lexmachina.com). However, one caveat of to these platforms is that many of they do not explain why they found particular cases relevant, and therefore, it is difficult to measure and benchmark their legal merit.
- In order to establish a benchmark for completeness, we need to capture an understanding of relevance in a legal context, case law in particular. 
  - One possible strategy to achieve this is to solicit legal experts to annotate court decision texts with information (e.g. legal principles, topics and arguments) that they use to evaluate case relevance. This strategy is  ideal for the long-term.
  - An alternative strategy in the short-term that demands less time and resources would be to select our base understanding for relevance to be equivalent to citation as captured in the *court decision citation network (CDCN)*. Accepting this notion of relevance, they compare it to several state-of-the-art text similarity algorithms used to create a *court decision similarity network (CDSN)*. That way, they can evaluate the size of the overlap between the two networks.
